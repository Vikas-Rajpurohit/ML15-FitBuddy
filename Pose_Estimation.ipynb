{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0af4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow tensorflow_hub opencv-contrib-python matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e54f11",
   "metadata": {},
   "source": [
    "nose, left eye, right eye, left ear, right ear, left shoulder, right shoulder, left elbow, right elbow, left wrist, right wrist, left hip, right hip, left knee, right knee, left ankle, right ankle]. The remaining 5 elements [ymin, xmin, ymax, xmax, score]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca1a96",
   "metadata": {},
   "source": [
    "The height/width are both multiple of 32.\n",
    "The height to width ratio is close (and enough) to cover the original image's aspect ratio.\n",
    "Make the larger side to be 256 (one should adjust this based on the speed/accuracy requirements). For example, a 720p image (i.e. 720x1280 (HxW)) should be resized and padded to 160x256 image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0b8167",
   "metadata": {},
   "source": [
    "Bench press, Pushup, Bicep Curl,\n",
    "Lateral Raise, Shoulder Press, and\n",
    "Squat,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd3bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\"models/recog.h5\")\n",
    "\n",
    "\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "523addb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mediapipe==0.9.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a45b362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d74569",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/thunder/4\")\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82364372",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}\n",
    "\n",
    "color_mapping = {\n",
    "    'r': (0, 0, 255),  # Red\n",
    "    'g': (0, 255, 0),  # Green\n",
    "    'b': (255, 0, 0),  # Blue\n",
    "    'y': (0, 255, 255),  # Yellow\n",
    "    'm': (255, 0, 255),  # Magenta\n",
    "    'c': (255, 255, 0)  # Cyan\n",
    "}\n",
    "\n",
    "target_dim = 512\n",
    "\n",
    "keypoint_names = [\n",
    "    \"nose\", \"left_eye\", \"right_eye\", \"left_ear\", \"right_ear\",\n",
    "    \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\",\n",
    "    \"left_wrist\", \"right_wrist\", \"left_hip\", \"right_hip\",\n",
    "    \"left_knee\", \"right_knee\", \"left_ankle\", \"right_ankle\"\n",
    "]\n",
    "\n",
    "remaining_elements = [\"ymin\", \"xmin\", \"ymax\", \"xmax\", \"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38e2f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_joints = [[\"left_shoulder\", \"left_elbow\", \"left_wrist\"], \n",
    "                [\"right_shoulder\", \"right_elbow\", \"right_wrist\"],]\n",
    "#                 [\"left_hip\", \"left_knee\", \"left_ankle\"],\n",
    "#                 [\"right_hip\", \"right_knee\", \"right_ankle\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "695ce6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    if height > width:\n",
    "        new_height = target_dim\n",
    "        new_width = int(width * (target_dim / height))\n",
    "        new_height = int(new_height // 32) * 32\n",
    "        new_width = int(new_width // 32) * 32\n",
    "    else:\n",
    "        new_width = target_dim\n",
    "        new_height = int(height * (target_dim / width))\n",
    "        new_height = int(new_height // 32) * 32\n",
    "        new_width = int(new_width // 32) * 32\n",
    "\n",
    "    frame = cv2.resize(frame, (new_width, new_height))\n",
    "    \n",
    "    return frame, new_width, new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82f5cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), color_mapping[color], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42037785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 3, (0,255,0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b105c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
    "    image = frame.copy()\n",
    "    \n",
    "    for person in keypoints_with_scores:\n",
    "        draw_connections(image, person, edges, confidence_threshold)\n",
    "        draw_keypoints(image, person, confidence_threshold)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1de5f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(frame, keypoints, total_joints):\n",
    "    y, x, c = frame.shape\n",
    "    for joint_names in total_joints:\n",
    "        a, b, c = [keypoints[joint] for joint in joint_names]\n",
    "#         ba = a - b\n",
    "#         bc = c - b\n",
    "#         cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "#         angle = np.arccos(cosine_angle)\n",
    "#         angle = int(np.degrees(angle))\n",
    "        \n",
    "        angleInRad = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "        angleInDeg = np.abs(angleInRad * 180.0 / np.pi)\n",
    "\n",
    "        angleInDeg = angleInDeg if angleInDeg <= 180 else 360 - angleInDeg\n",
    "\n",
    "        cv2.putText(frame, str(int(angleInDeg)), (int(b[1]*x),int(b[0]*y)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,0,255), 2)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ea9a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_dict_bp(keypoints):\n",
    "    cnt = 0\n",
    "    final_dict = {}\n",
    "    \n",
    "    new_kp = keypoints\n",
    "    \n",
    "#     new_kp = []\n",
    "#     for kp in keypoints[0]:\n",
    "#         if kp[55] > 0.1:\n",
    "#             cnt += 1\n",
    "#             new_kp.append(kp)\n",
    "            \n",
    "#     new_kp = np.asarray(new_kp)\n",
    "    \n",
    "    if len(new_kp) > 0:\n",
    "        keypoints_with_scores = new_kp[:,:51].reshape((1,17,3))\n",
    "    \n",
    "        for idx,person_kp in enumerate(keypoints_with_scores):\n",
    "            body_points = {}\n",
    "            for i,name in enumerate(keypoint_names):\n",
    "                body_points[name] = person_kp[i]\n",
    "\n",
    "            final_dict[idx] = body_points\n",
    "        \n",
    "        return keypoints_with_scores, final_dict\n",
    "    else:\n",
    "        return -1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9bb1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recog(image):\n",
    "    frame = image.copy()\n",
    "    \n",
    "    pad = 30\n",
    "    h,w,_ = frame.shape\n",
    "    \n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(frame_rgb)\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        img = frame.copy()\n",
    "        # Loop through each detected hand\n",
    "        x_min, y_min, x_max, y_max = float('inf'), float('inf'), -float('inf'), -float('inf')\n",
    "        \n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Extract hand bounding box coordinates\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                x, y, _ = int(landmark.x * w), int(landmark.y * h), landmark.z\n",
    "                x_min = min(x_min, x)\n",
    "                y_min = min(y_min, y)\n",
    "                x_max = max(x_max, x)\n",
    "                y_max = max(y_max, y)\n",
    "\n",
    "        # Crop the hand from the frame\n",
    "        hand_crop = img[y_min-pad:y_max+pad,x_min-pad:x_max+pad]\n",
    "        \n",
    "        # Resize the frame\n",
    "        if 0 not in hand_crop.shape:\n",
    "    \n",
    "            resized_hand = cv2.resize(hand_crop, (250, 250))\n",
    "            image = np.expand_dims(resized_hand, axis=0)\n",
    "        \n",
    "            class_probabilities = loaded_model.predict(image, verbose=False)\n",
    "\n",
    "            prc = np.argmax(class_probabilities)\n",
    "            \n",
    "            if prc != -1:\n",
    "                if prc == 0:\n",
    "                    cv2.putText(frame, 'Bicep Curls',(100,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                else:\n",
    "                    cv2.putText(frame, 'Shoulder Press',(100,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow('Recognition', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30348867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4cb51e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from utils import detect_bicep_curls, detect_pushup, detect_shoulder, detect_squats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4f10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0af68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941c9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9c25f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_sources = {\n",
    "    \"Bicep Curls\": 0, \n",
    "    \"Push Ups\": \"videos/adi_pushup.mp4\",\n",
    "    \"Shoulder Press\": 0,  \n",
    "    \"Squats\": \"videos/adi_squat.mp4\"\n",
    "}\n",
    "\n",
    "def run_exercise_detection(exercise):\n",
    "    # Define the video source based on the selected exercise\n",
    "    cap = cv2.VideoCapture(video_sources.get(exercise, 0))  # Default to webcam (0) if exercise not found\n",
    "\n",
    "    rep_cnt = 0\n",
    "    prev_rep = False\n",
    "    fault = False\n",
    "\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, in_frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "          \n",
    "#         recog(in_frame)\n",
    "        \n",
    "        frame, _ , _ = preprocess_frame(in_frame)\n",
    "\n",
    "        # Resize image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 256, 256)\n",
    "        input_img = tf.cast(img, dtype=tf.int32)\n",
    "\n",
    "        # Detection section (Replace with your exercise-specific detection functions)\n",
    "        results = movenet(input_img)\n",
    "        keypoints = results['output_0'].numpy()\n",
    "        keypoints = np.reshape(keypoints, (1, 1, 51))\n",
    "\n",
    "        if final_dict_bp(keypoints) != -1:\n",
    "            keypoints_with_scores, final_dict = final_dict_bp(keypoints)\n",
    "    \n",
    "            value = final_dict[0]\n",
    "\n",
    "            # Render keypoints\n",
    "            image = loop_through_people(frame, keypoints_with_scores, EDGES, 0.1)\n",
    "            \n",
    "        # Add your exercise-specific detection functions here\n",
    "            if exercise == \"Bicep Curls\":\n",
    "                bicep_img, rep_cnt, prev_rep, fault = detect_bicep_curls(frame, value, rep_cnt, prev_rep, fault)\n",
    "                horizontal_concat = np.concatenate((bicep_img, image), axis=1)\n",
    "                cv2.imshow('Bicep Curls', horizontal_concat)\n",
    "                key = cv2.waitKey(10) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "            elif exercise == \"Push Ups\":\n",
    "                push_img, rep_cnt, prev_rep, fault = detect_pushup(frame, value, rep_cnt, prev_rep, fault)\n",
    "                horizontal_concat = np.concatenate((push_img, image), axis=1)\n",
    "                cv2.imshow('Push Ups', horizontal_concat)\n",
    "                key = cv2.waitKey(10) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                \n",
    "            elif exercise == \"Shoulder Press\":\n",
    "                shoulder_img, rep_cnt, prev_rep, fault = detect_shoulder(frame, value, rep_cnt, prev_rep, fault)\n",
    "                horizontal_concat = np.concatenate((shoulder_img, image), axis=1)\n",
    "                cv2.imshow('Shoulder Press', horizontal_concat)\n",
    "                key = cv2.waitKey(10) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                \n",
    "            elif exercise == \"Squats\":\n",
    "                squat_img, rep_cnt, prev_rep, fault = detect_squats(frame, value, rep_cnt, prev_rep, fault)\n",
    "                horizontal_concat = np.concatenate((squat_img, image), axis=1)\n",
    "                cv2.imshow('Squats', horizontal_concat)\n",
    "                key = cv2.waitKey(10) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7ec7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = [\"Bicep Curls\",\"Push Ups\", \"Shoulder Press\", \"Squats\"]\n",
    "\n",
    "run_exercise_detection(choices[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb433ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f6dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9cc82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "djsc",
   "language": "python",
   "name": "djsc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
